{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyUuTp2n5ShY",
        "outputId": "aeda1dbb-9211-4b7f-d649-650b73ab5490"
      },
      "source": [
        "#user defined\n",
        "%cd folder_of_code_and_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1hGjY8lqo0ImpPj9LC-v5HRrtHXy2RCOo/spatialnet_test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "-pYVEj0widVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import functions from .py files"
      ],
      "metadata": {
        "id": "5_HYw3vaP2b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "'''STAR'''\n",
        "'''Can be easily customized with the template'''\n",
        "from models import DNNmodel, UNetmodel#model is easily customizable\n",
        "# from customize import generate_groups#can customize group definition\n",
        "from data import *\n",
        "from initialization import init_X_info\n",
        "from helper import create_dir, open_dir\n",
        "from transformation import partition\n",
        "# from visualization import *\n",
        "'''All global parameters'''\n",
        "from paras import *"
      ],
      "metadata": {
        "id": "lL7drrh9ybwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare directory for results (weights, data partitions, etc.)\n",
        "If create a new directory:"
      ],
      "metadata": {
        "id": "p4Mftk7gPw-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Create directories'''\n",
        "model_dir, dir, dir_ckpt = create_dir()"
      ],
      "metadata": {
        "id": "O7CBIUM8yY0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If loading from an existing (trained) directory:"
      ],
      "metadata": {
        "id": "BOiVSopbQPrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Open existing directories'''\n",
        "model_dir = 'result_auto_10'\n",
        "dir, dir_ckpt = open_dir(model_dir)"
      ],
      "metadata": {
        "id": "gmG-VDKkPu3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data\n",
        "* This example uses spatial data (satellite imagery tile: split into smaller patches). The task is semantic segmentation (crop classification).\n",
        "* For general spatial data or non-spatial data, see customize.py\n",
        "    * Mostly only a unit-grouping function needs to be customized"
      ],
      "metadata": {
        "id": "NURA4Uv3mCF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Load data'''\n",
        "#data urls are provided in github for downloading: https://github.com/ai-spatial/STAR\n",
        "X_path = 'X_example.npy'\n",
        "y_path = 'y_example.npy'\n",
        "#semantic segmentation (each sample is an image patch)\n",
        "X, y, X_loc = load_data_seg(X_path = X_path, y_path = y_path, return_loc = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6bxkhnqs3LS",
        "outputId": "ec525f20-ca14-494d-e4a3-7e84d55e8546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_patch: 961 , cnt: 961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(X_loc.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqnrwHhVB2Yi",
        "outputId": "f743c6a4-e22e-43b6-b3d7-efd7a80d0eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(961, 128, 128, 10)\n",
            "(961, 128, 128, 23)\n",
            "(961, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initialization"
      ],
      "metadata": {
        "id": "6abheHE-RNff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Initialize location-related and training information. Can be customized.\n",
        "      X_id stores data points' ids in the original X, and is used as a reference.\n",
        "      X_set stores train-val-test assignments: train=0, val=1, test=2\n",
        "      X_branch_id stores branch_ids (or, partion ids) of each data points. All init to route branch ''. Dynamically updated during training.\n",
        "      X_group stores group assignment: customizable. In this example, groups are defined by grid cells in space.\n",
        "'''\n",
        "\n",
        "X_group, X_set, X_id, X_branch_id = init_X_info(X, y, X_loc = X_loc)"
      ],
      "metadata": {
        "id": "AzTVEv2EyYHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training\n",
        "This step trains a plain UNet model to get the weights stablized before learning how to partition data into homogeneous sets (i.e., all samples in a set follows the same function X->y)."
      ],
      "metadata": {
        "id": "XPQ0byorl3vB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Train to stablize before starting the first data partitioning'''\n",
        "train_list_init = np.where(X_set == 0)\n",
        "model = UNetmodel(ckpt_path = dir_ckpt, training = True)\n",
        "model.model_compile()\n",
        "model.train(X[train_list_init], y[train_list_init], branch_id = '', \n",
        "            train_type = 'plain')#'' is the root branch (before any splits)\n",
        "model.save('')#save root branch"
      ],
      "metadata": {
        "id": "DihPLKg_oOWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79659904-05e9-40dd-84e7-6369408721a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check ckpt path: result_auto_24/checkpoints\n",
            "Epoch 1/40\n",
            "4/4 [==============================] - 15s 357ms/step - loss: 3.3212 - accuracy: 0.0455\n",
            "Epoch 2/40\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 3.2001 - accuracy: 0.0619\n",
            "Epoch 3/40\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 3.0965 - accuracy: 0.0813\n",
            "Epoch 4/40\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 2.9999 - accuracy: 0.1072\n",
            "Epoch 5/40\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 2.9109 - accuracy: 0.1395\n",
            "Epoch 6/40\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 2.8286 - accuracy: 0.1769\n",
            "Epoch 7/40\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 2.7557 - accuracy: 0.2143\n",
            "Epoch 8/40\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 2.6835 - accuracy: 0.2503\n",
            "Epoch 9/40\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 2.6178 - accuracy: 0.2841\n",
            "Epoch 10/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 2.5515 - accuracy: 0.3178\n",
            "Epoch 11/40\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 2.4982 - accuracy: 0.3444\n",
            "Epoch 12/40\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 2.4343 - accuracy: 0.3770\n",
            "Epoch 13/40\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 2.3875 - accuracy: 0.3952\n",
            "Epoch 14/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 2.3272 - accuracy: 0.4169\n",
            "Epoch 15/40\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 2.2841 - accuracy: 0.4284\n",
            "Epoch 16/40\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 2.2394 - accuracy: 0.4411\n",
            "Epoch 17/40\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 2.1944 - accuracy: 0.4578\n",
            "Epoch 18/40\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 2.1502 - accuracy: 0.4695\n",
            "Epoch 19/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 2.1214 - accuracy: 0.4751\n",
            "Epoch 20/40\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 2.0809 - accuracy: 0.4889\n",
            "Epoch 21/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 2.0497 - accuracy: 0.4955\n",
            "Epoch 22/40\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 2.0182 - accuracy: 0.5065\n",
            "Epoch 23/40\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 2.0057 - accuracy: 0.5097\n",
            "Epoch 24/40\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 1.9634 - accuracy: 0.5233\n",
            "Epoch 25/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 1.9318 - accuracy: 0.5318\n",
            "Epoch 26/40\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 1.9075 - accuracy: 0.5335\n",
            "Epoch 27/40\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 1.8909 - accuracy: 0.5400\n",
            "Epoch 28/40\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 1.8668 - accuracy: 0.5441\n",
            "Epoch 29/40\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 1.8520 - accuracy: 0.5435\n",
            "Epoch 30/40\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 1.8277 - accuracy: 0.5520\n",
            "Epoch 31/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 1.8056 - accuracy: 0.5564\n",
            "Epoch 32/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 1.7869 - accuracy: 0.5610\n",
            "Epoch 33/40\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 1.7680 - accuracy: 0.5655\n",
            "Epoch 34/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 1.7453 - accuracy: 0.5697\n",
            "Epoch 35/40\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 1.7314 - accuracy: 0.5722\n",
            "Epoch 36/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 1.7235 - accuracy: 0.5711\n",
            "Epoch 37/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 1.7146 - accuracy: 0.5726\n",
            "Epoch 38/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 1.7122 - accuracy: 0.5735\n",
            "Epoch 39/40\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 1.6838 - accuracy: 0.5821\n",
            "Epoch 40/40\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 1.6901 - accuracy: 0.5755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Heterogeneity-aware training\n",
        "Learns the data partitioning and transform the network architecture based on that."
      ],
      "metadata": {
        "id": "JnVq1POwSvNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Spatial transformation (data partitioning, not necessarily for spatial data).\n",
        "This will automatically partition data into subsets during training, so that each subset follows a homogeneous distribution.\n",
        "format of branch_id: for example: '0010' refers to a branch after four bi-partitionings (four splits),\n",
        "    and 0 or 1 shows the partition it belongs to after each split.\n",
        "    '' is the root branch (before any split).\n",
        "s_branch: another key output, that stores the group ids for all branches.\n",
        "X_branch_id: contains the branch_id for each data point.\n",
        "branch_table: shows which branches are further split and which are not.\n",
        "'''\n",
        "model.model = model.create_net(training = False)\n",
        "model.model_compile()\n",
        "X_branch_id, branch_table, s_branch = partition(model, X, y,\n",
        "                     X_group , X_set, X_id, X_branch_id,\n",
        "                     max_depth = MAX_DEPTH)#partition data to subsets following homogeneous distributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrfsWeQd0Su9",
        "outputId": "c708ccbe-e757-425e-aa76-a0be428be103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level 0 --------------------------------------------------\n",
            "Level 0 -- branch:  --------------------------------------------------\n",
            "6/6 [==============================] - 1s 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1hGjY8lqo0ImpPj9LC-v5HRrtHXy2RCOo/spatialnet_test/1python_code/partition_opt.py:179: RuntimeWarning: invalid value encountered in true_divide\n",
            "  q_init = np.nan_to_num(c/b)\n",
            "/content/drive/.shortcut-targets-by-id/1hGjY8lqo0ImpPj9LC-v5HRrtHXy2RCOo/spatialnet_test/1python_code/partition_opt.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
            "  q = np.nan_to_num(np.sum(c[s0],0) / np.sum(b[s0],0))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_lr < 0: check initialization!\n",
            "Training new branches...\n",
            "Training branch 0:\n",
            "2\n",
            "Epoch 1/40\n",
            "2/2 [==============================] - 4s 2s/step - loss: 2.4281 - accuracy: 0.3199\n",
            "Epoch 2/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 2.3927 - accuracy: 0.3472\n",
            "Epoch 3/40\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 2.3268 - accuracy: 0.3703\n",
            "Epoch 4/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 2.2549 - accuracy: 0.3734\n",
            "Epoch 5/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 2.1799 - accuracy: 0.3771\n",
            "Epoch 6/40\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 2.1182 - accuracy: 0.3991\n",
            "Epoch 7/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 2.0614 - accuracy: 0.4402\n",
            "Epoch 8/40\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 2.0104 - accuracy: 0.4687\n",
            "Epoch 9/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.9767 - accuracy: 0.4738\n",
            "Epoch 10/40\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 1.9402 - accuracy: 0.4750\n",
            "Epoch 11/40\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 1.9089 - accuracy: 0.4748\n",
            "Epoch 12/40\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 1.8813 - accuracy: 0.4737\n",
            "Epoch 13/40\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 1.8519 - accuracy: 0.4784\n",
            "Epoch 14/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.8385 - accuracy: 0.4790\n",
            "Epoch 15/40\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 1.8178 - accuracy: 0.4811\n",
            "Epoch 16/40\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 1.8029 - accuracy: 0.4847\n",
            "Epoch 17/40\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 1.7819 - accuracy: 0.4910\n",
            "Epoch 18/40\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 1.7640 - accuracy: 0.4950\n",
            "Epoch 19/40\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 1.7478 - accuracy: 0.4981\n",
            "Epoch 20/40\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 1.7314 - accuracy: 0.5018\n",
            "Epoch 21/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.7157 - accuracy: 0.5058\n",
            "Epoch 22/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.6989 - accuracy: 0.5100\n",
            "Epoch 23/40\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 1.6858 - accuracy: 0.5122\n",
            "Epoch 24/40\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 1.6706 - accuracy: 0.5151\n",
            "Epoch 25/40\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 1.6625 - accuracy: 0.5167\n",
            "Epoch 26/40\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 1.6483 - accuracy: 0.5208\n",
            "Epoch 27/40\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 1.6335 - accuracy: 0.5239\n",
            "Epoch 28/40\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 1.6240 - accuracy: 0.5250\n",
            "Epoch 29/40\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 1.6102 - accuracy: 0.5304\n",
            "Epoch 30/40\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 1.5977 - accuracy: 0.5331\n",
            "Epoch 31/40\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 1.5922 - accuracy: 0.5332\n",
            "Epoch 32/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.5790 - accuracy: 0.5380\n",
            "Epoch 33/40\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 1.5691 - accuracy: 0.5392\n",
            "Epoch 34/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.5581 - accuracy: 0.5440\n",
            "Epoch 35/40\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 1.5533 - accuracy: 0.5436\n",
            "Epoch 36/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.5439 - accuracy: 0.5460\n",
            "Epoch 37/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.5315 - accuracy: 0.5488\n",
            "Epoch 38/40\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 1.5281 - accuracy: 0.5506\n",
            "Epoch 39/40\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 1.5178 - accuracy: 0.5511\n",
            "Epoch 40/40\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 1.5083 - accuracy: 0.5541\n",
            "4/4 [==============================] - 0s 29ms/step\n",
            "Training branch 1:\n",
            "2\n",
            "Epoch 1/40\n",
            "2/2 [==============================] - 2s 1s/step - loss: 2.3286 - accuracy: 0.4255\n",
            "Epoch 2/40\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 2.2399 - accuracy: 0.4420\n",
            "Epoch 3/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 2.1635 - accuracy: 0.4508\n",
            "Epoch 4/40\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 2.1039 - accuracy: 0.4511\n",
            "Epoch 5/40\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 2.0419 - accuracy: 0.4499\n",
            "Epoch 6/40\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 1.9789 - accuracy: 0.4542\n",
            "Epoch 7/40\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 1.9223 - accuracy: 0.4653\n",
            "Epoch 8/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.8584 - accuracy: 0.4914\n",
            "Epoch 9/40\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 1.8127 - accuracy: 0.5363\n",
            "Epoch 10/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.7773 - accuracy: 0.5544\n",
            "Epoch 11/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.7307 - accuracy: 0.5614\n",
            "Epoch 12/40\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 1.6824 - accuracy: 0.5677\n",
            "Epoch 13/40\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 1.6518 - accuracy: 0.5739\n",
            "Epoch 14/40\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 1.6234 - accuracy: 0.5789\n",
            "Epoch 15/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.5987 - accuracy: 0.5808\n",
            "Epoch 16/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.5768 - accuracy: 0.5825\n",
            "Epoch 17/40\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 1.5539 - accuracy: 0.5872\n",
            "Epoch 18/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.5321 - accuracy: 0.5902\n",
            "Epoch 19/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.5077 - accuracy: 0.5923\n",
            "Epoch 20/40\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 1.4940 - accuracy: 0.5946\n",
            "Epoch 21/40\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 1.4725 - accuracy: 0.5988\n",
            "Epoch 22/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.4567 - accuracy: 0.6062\n",
            "Epoch 23/40\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 1.4367 - accuracy: 0.6095\n",
            "Epoch 24/40\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 1.4217 - accuracy: 0.6140\n",
            "Epoch 25/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.4061 - accuracy: 0.6195\n",
            "Epoch 26/40\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 1.3903 - accuracy: 0.6229\n",
            "Epoch 27/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.3744 - accuracy: 0.6253\n",
            "Epoch 28/40\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 1.3600 - accuracy: 0.6292\n",
            "Epoch 29/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.3557 - accuracy: 0.6287\n",
            "Epoch 30/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.3456 - accuracy: 0.6337\n",
            "Epoch 31/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.3350 - accuracy: 0.6356\n",
            "Epoch 32/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.3303 - accuracy: 0.6377\n",
            "Epoch 33/40\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 1.3157 - accuracy: 0.6427\n",
            "Epoch 34/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.3073 - accuracy: 0.6446\n",
            "Epoch 35/40\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 1.2999 - accuracy: 0.6475\n",
            "Epoch 36/40\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.2934 - accuracy: 0.6486\n",
            "Epoch 37/40\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.2814 - accuracy: 0.6512\n",
            "Epoch 38/40\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 1.2850 - accuracy: 0.6513\n",
            "Epoch 39/40\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 1.2753 - accuracy: 0.6531\n",
            "Epoch 40/40\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 1.2613 - accuracy: 0.6572\n",
            "3/3 [==============================] - 1s 388ms/step\n",
            "Smaller than MIN_DEPTH, split directly...\n",
            "+ Split  into 0, 1\n",
            "Level 1 --------------------------------------------------\n",
            "Level 1 -- branch: 0 --------------------------------------------------\n",
            "4/4 [==============================] - 0s 29ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1hGjY8lqo0ImpPj9LC-v5HRrtHXy2RCOo/spatialnet_test/1python_code/partition_opt.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "  b = np.expand_dims(c_tot,0) * (base / np.expand_dims(base_tot,0))\n",
            "/content/drive/.shortcut-targets-by-id/1hGjY8lqo0ImpPj9LC-v5HRrtHXy2RCOo/spatialnet_test/1python_code/partition_opt.py:183: RuntimeWarning: invalid value encountered in true_divide\n",
            "  q[i] = np.sum(c[s_class,i]) / np.sum(b[s_class,i])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_lr < 0: check initialization!\n",
            "Training new branches...\n",
            "Training branch 0:\n",
            "2\n",
            "Epoch 41/80\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.5889 - accuracy: 0.5366\n",
            "Epoch 42/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.5806 - accuracy: 0.5391\n",
            "Epoch 43/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.5809 - accuracy: 0.5410\n",
            "Epoch 44/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.5739 - accuracy: 0.5461\n",
            "Epoch 45/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.5615 - accuracy: 0.5479\n",
            "Epoch 46/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.5627 - accuracy: 0.5461\n",
            "Epoch 47/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.5465 - accuracy: 0.5515\n",
            "Epoch 48/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.5481 - accuracy: 0.5507\n",
            "Epoch 49/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.5348 - accuracy: 0.5563\n",
            "Epoch 50/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.5308 - accuracy: 0.5578\n",
            "Epoch 51/80\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.5251 - accuracy: 0.5584\n",
            "Epoch 52/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.5155 - accuracy: 0.5629\n",
            "Epoch 53/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.5124 - accuracy: 0.5666\n",
            "Epoch 54/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.5022 - accuracy: 0.5675\n",
            "Epoch 55/80\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.4997 - accuracy: 0.5649\n",
            "Epoch 56/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.4937 - accuracy: 0.5691\n",
            "Epoch 57/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.4822 - accuracy: 0.5746\n",
            "Epoch 58/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.4808 - accuracy: 0.5743\n",
            "Epoch 59/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.4726 - accuracy: 0.5820\n",
            "Epoch 60/80\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.4645 - accuracy: 0.5831\n",
            "Epoch 61/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.4594 - accuracy: 0.5830\n",
            "Epoch 62/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.4573 - accuracy: 0.5877\n",
            "Epoch 63/80\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.4457 - accuracy: 0.5879\n",
            "Epoch 64/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.4395 - accuracy: 0.5904\n",
            "Epoch 65/80\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.4357 - accuracy: 0.5944\n",
            "Epoch 66/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.4326 - accuracy: 0.5911\n",
            "Epoch 67/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.4268 - accuracy: 0.5986\n",
            "Epoch 68/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.4165 - accuracy: 0.5978\n",
            "Epoch 69/80\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.4070 - accuracy: 0.6030\n",
            "Epoch 70/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.4020 - accuracy: 0.6048\n",
            "Epoch 71/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.3979 - accuracy: 0.6038\n",
            "Epoch 72/80\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.4014 - accuracy: 0.6064\n",
            "Epoch 73/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.4109 - accuracy: 0.5948\n",
            "Epoch 74/80\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.4367 - accuracy: 0.5929\n",
            "Epoch 75/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.3801 - accuracy: 0.6092\n",
            "Epoch 76/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.3939 - accuracy: 0.6010\n",
            "Epoch 77/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.4117 - accuracy: 0.6030\n",
            "Epoch 78/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.3653 - accuracy: 0.6176\n",
            "Epoch 79/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.4097 - accuracy: 0.5918\n",
            "Epoch 80/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.3702 - accuracy: 0.6168\n",
            "2/2 [==============================] - 1s 536ms/step\n",
            "Training branch 1:\n",
            "2\n",
            "Epoch 41/80\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.4188 - accuracy: 0.5776\n",
            "Epoch 42/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.4045 - accuracy: 0.5827\n",
            "Epoch 43/80\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 1.3998 - accuracy: 0.5869\n",
            "Epoch 44/80\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.3920 - accuracy: 0.5884\n",
            "Epoch 45/80\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.3871 - accuracy: 0.5882\n",
            "Epoch 46/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.3731 - accuracy: 0.5960\n",
            "Epoch 47/80\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 1.3725 - accuracy: 0.5945\n",
            "Epoch 48/80\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.3577 - accuracy: 0.6014\n",
            "Epoch 49/80\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.3538 - accuracy: 0.5996\n",
            "Epoch 50/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.3427 - accuracy: 0.6055\n",
            "Epoch 51/80\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.3392 - accuracy: 0.6048\n",
            "Epoch 52/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.3287 - accuracy: 0.6099\n",
            "Epoch 53/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.3228 - accuracy: 0.6113\n",
            "Epoch 54/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.3172 - accuracy: 0.6112\n",
            "Epoch 55/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.3070 - accuracy: 0.6151\n",
            "Epoch 56/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.3027 - accuracy: 0.6159\n",
            "Epoch 57/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2941 - accuracy: 0.6190\n",
            "Epoch 58/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.2870 - accuracy: 0.6213\n",
            "Epoch 59/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.2824 - accuracy: 0.6215\n",
            "Epoch 60/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.2748 - accuracy: 0.6233\n",
            "Epoch 61/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.2666 - accuracy: 0.6255\n",
            "Epoch 62/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.2621 - accuracy: 0.6272\n",
            "Epoch 63/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.2567 - accuracy: 0.6272\n",
            "Epoch 64/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.2501 - accuracy: 0.6287\n",
            "Epoch 65/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.2427 - accuracy: 0.6301\n",
            "Epoch 66/80\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 1.2346 - accuracy: 0.6325\n",
            "Epoch 67/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.2292 - accuracy: 0.6343\n",
            "Epoch 68/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.2238 - accuracy: 0.6352\n",
            "Epoch 69/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.2199 - accuracy: 0.6352\n",
            "Epoch 70/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.2172 - accuracy: 0.6357\n",
            "Epoch 71/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.2164 - accuracy: 0.6346\n",
            "Epoch 72/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.2111 - accuracy: 0.6361\n",
            "Epoch 73/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2013 - accuracy: 0.6392\n",
            "Epoch 74/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.1882 - accuracy: 0.6433\n",
            "Epoch 75/80\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.1819 - accuracy: 0.6451\n",
            "Epoch 76/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.1824 - accuracy: 0.6444\n",
            "Epoch 77/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.1771 - accuracy: 0.6446\n",
            "Epoch 78/80\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.1676 - accuracy: 0.6476\n",
            "Epoch 79/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.1571 - accuracy: 0.6514\n",
            "Epoch 80/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.1543 - accuracy: 0.6525\n",
            "2/2 [==============================] - 1s 486ms/step\n",
            "Smaller than MIN_DEPTH, split directly...\n",
            "+ Split 0 into 00, 01\n",
            "Level 1 -- branch: 1 --------------------------------------------------\n",
            "3/3 [==============================] - 0s 30ms/step\n",
            "log_lr < 0: check initialization!\n",
            "Training new branches...\n",
            "Training branch 0:\n",
            "2\n",
            "Epoch 41/80\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 1.4071 - accuracy: 0.6121\n",
            "Epoch 42/80\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.3879 - accuracy: 0.6202\n",
            "Epoch 43/80\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.3916 - accuracy: 0.6200\n",
            "Epoch 44/80\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.3827 - accuracy: 0.6208\n",
            "Epoch 45/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.3740 - accuracy: 0.6220\n",
            "Epoch 46/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.3738 - accuracy: 0.6225\n",
            "Epoch 47/80\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.3620 - accuracy: 0.6249\n",
            "Epoch 48/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.3630 - accuracy: 0.6257\n",
            "Epoch 49/80\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.3534 - accuracy: 0.6277\n",
            "Epoch 50/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.3478 - accuracy: 0.6280\n",
            "Epoch 51/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.3451 - accuracy: 0.6280\n",
            "Epoch 52/80\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.3366 - accuracy: 0.6298\n",
            "Epoch 53/80\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.3358 - accuracy: 0.6297\n",
            "Epoch 54/80\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.3282 - accuracy: 0.6310\n",
            "Epoch 55/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.3254 - accuracy: 0.6310\n",
            "Epoch 56/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.3186 - accuracy: 0.6326\n",
            "Epoch 57/80\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.3150 - accuracy: 0.6344\n",
            "Epoch 58/80\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.3101 - accuracy: 0.6355\n",
            "Epoch 59/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.3044 - accuracy: 0.6359\n",
            "Epoch 60/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.3021 - accuracy: 0.6364\n",
            "Epoch 61/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.2963 - accuracy: 0.6378\n",
            "Epoch 62/80\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.2932 - accuracy: 0.6389\n",
            "Epoch 63/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2877 - accuracy: 0.6397\n",
            "Epoch 64/80\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.2842 - accuracy: 0.6399\n",
            "Epoch 65/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.2788 - accuracy: 0.6411\n",
            "Epoch 66/80\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.2757 - accuracy: 0.6419\n",
            "Epoch 67/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2705 - accuracy: 0.6429\n",
            "Epoch 68/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2671 - accuracy: 0.6439\n",
            "Epoch 69/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.2624 - accuracy: 0.6451\n",
            "Epoch 70/80\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.2581 - accuracy: 0.6465\n",
            "Epoch 71/80\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.2545 - accuracy: 0.6475\n",
            "Epoch 72/80\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.2497 - accuracy: 0.6491\n",
            "Epoch 73/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2465 - accuracy: 0.6504\n",
            "Epoch 74/80\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.2419 - accuracy: 0.6517\n",
            "Epoch 75/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.2378 - accuracy: 0.6530\n",
            "Epoch 76/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2340 - accuracy: 0.6540\n",
            "Epoch 77/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.2293 - accuracy: 0.6551\n",
            "Epoch 78/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2257 - accuracy: 0.6562\n",
            "Epoch 79/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.2218 - accuracy: 0.6573\n",
            "Epoch 80/80\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.2174 - accuracy: 0.6589\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "Training branch 1:\n",
            "2\n",
            "Epoch 41/80\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.1296 - accuracy: 0.6987\n",
            "Epoch 42/80\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.1066 - accuracy: 0.7029\n",
            "Epoch 43/80\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 1.1046 - accuracy: 0.7010\n",
            "Epoch 44/80\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.1060 - accuracy: 0.7002\n",
            "Epoch 45/80\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.0923 - accuracy: 0.7053\n",
            "Epoch 46/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0844 - accuracy: 0.7083\n",
            "Epoch 47/80\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.0833 - accuracy: 0.7071\n",
            "Epoch 48/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.0744 - accuracy: 0.7076\n",
            "Epoch 49/80\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.0678 - accuracy: 0.7092\n",
            "Epoch 50/80\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 1.0630 - accuracy: 0.7115\n",
            "Epoch 51/80\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.0577 - accuracy: 0.7135\n",
            "Epoch 52/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0531 - accuracy: 0.7151\n",
            "Epoch 53/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.0448 - accuracy: 0.7164\n",
            "Epoch 54/80\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.0409 - accuracy: 0.7154\n",
            "Epoch 55/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0387 - accuracy: 0.7154\n",
            "Epoch 56/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.0295 - accuracy: 0.7190\n",
            "Epoch 57/80\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 1.0260 - accuracy: 0.7212\n",
            "Epoch 58/80\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 1.0231 - accuracy: 0.7223\n",
            "Epoch 59/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0160 - accuracy: 0.7236\n",
            "Epoch 60/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.0117 - accuracy: 0.7237\n",
            "Epoch 61/80\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0079 - accuracy: 0.7238\n",
            "Epoch 62/80\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.0038 - accuracy: 0.7251\n",
            "Epoch 63/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.9981 - accuracy: 0.7274\n",
            "Epoch 64/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.9958 - accuracy: 0.7280\n",
            "Epoch 65/80\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.9908 - accuracy: 0.7291\n",
            "Epoch 66/80\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.9862 - accuracy: 0.7298\n",
            "Epoch 67/80\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.9826 - accuracy: 0.7303\n",
            "Epoch 68/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.9780 - accuracy: 0.7319\n",
            "Epoch 69/80\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.9732 - accuracy: 0.7336\n",
            "Epoch 70/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.9696 - accuracy: 0.7346\n",
            "Epoch 71/80\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.9646 - accuracy: 0.7358\n",
            "Epoch 72/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.9605 - accuracy: 0.7367\n",
            "Epoch 73/80\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.9564 - accuracy: 0.7374\n",
            "Epoch 74/80\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.9520 - accuracy: 0.7387\n",
            "Epoch 75/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.9477 - accuracy: 0.7403\n",
            "Epoch 76/80\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.9435 - accuracy: 0.7417\n",
            "Epoch 77/80\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.9388 - accuracy: 0.7428\n",
            "Epoch 78/80\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.9345 - accuracy: 0.7442\n",
            "Epoch 79/80\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.9300 - accuracy: 0.7458\n",
            "Epoch 80/80\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.9258 - accuracy: 0.7472\n",
            "2/2 [==============================] - 1s 510ms/step\n",
            "Smaller than MIN_DEPTH, split directly...\n",
            "+ Split 1 into 10, 11\n",
            "Level 2 --------------------------------------------------\n",
            "Level 2 -- branch: 00 --------------------------------------------------\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "Training new branches...\n",
            "Training branch 0:\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.4129 - accuracy: 0.6041\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1.4373 - accuracy: 0.5808\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.3647 - accuracy: 0.6203\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.3872 - accuracy: 0.6159\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.3516 - accuracy: 0.6185\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1.3538 - accuracy: 0.6160\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.3441 - accuracy: 0.6266\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.3335 - accuracy: 0.6299\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.3266 - accuracy: 0.6260\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.3131 - accuracy: 0.6330\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.3099 - accuracy: 0.6361\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.2979 - accuracy: 0.6418\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1.2959 - accuracy: 0.6381\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.2792 - accuracy: 0.6464\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.2800 - accuracy: 0.6466\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.2654 - accuracy: 0.6525\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.2664 - accuracy: 0.6496\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.2507 - accuracy: 0.6580\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.2505 - accuracy: 0.6587\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.2382 - accuracy: 0.6615\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.2350 - accuracy: 0.6610\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.2277 - accuracy: 0.6658\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.2200 - accuracy: 0.6686\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.2169 - accuracy: 0.6667\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.2070 - accuracy: 0.6720\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.2028 - accuracy: 0.6740\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.1962 - accuracy: 0.6734\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.1900 - accuracy: 0.6772\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.1834 - accuracy: 0.6796\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.1768 - accuracy: 0.6806\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.1733 - accuracy: 0.6818\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.1654 - accuracy: 0.6846\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.1582 - accuracy: 0.6869\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.1555 - accuracy: 0.6879\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.1494 - accuracy: 0.6891\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.1421 - accuracy: 0.6923\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1.1373 - accuracy: 0.6929\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.1313 - accuracy: 0.6956\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.1245 - accuracy: 0.6980\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.1199 - accuracy: 0.6987\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Training branch 1:\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3439 - accuracy: 0.6243\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.3299 - accuracy: 0.6247\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.3348 - accuracy: 0.6199\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.3182 - accuracy: 0.6288\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.3197 - accuracy: 0.6285\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.3044 - accuracy: 0.6329\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.3035 - accuracy: 0.6301\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.2909 - accuracy: 0.6361\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.2880 - accuracy: 0.6386\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.2768 - accuracy: 0.6407\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.2729 - accuracy: 0.6396\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.2631 - accuracy: 0.6433\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.2591 - accuracy: 0.6459\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.2485 - accuracy: 0.6478\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.2453 - accuracy: 0.6465\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.2352 - accuracy: 0.6511\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.2320 - accuracy: 0.6530\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.2231 - accuracy: 0.6527\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.2177 - accuracy: 0.6542\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.2118 - accuracy: 0.6570\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.2041 - accuracy: 0.6567\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.1986 - accuracy: 0.6577\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.1934 - accuracy: 0.6605\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.1853 - accuracy: 0.6611\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.1810 - accuracy: 0.6610\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.1753 - accuracy: 0.6635\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.1692 - accuracy: 0.6634\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.1623 - accuracy: 0.6649\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.1570 - accuracy: 0.6662\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.1530 - accuracy: 0.6663\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.1473 - accuracy: 0.6687\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.1420 - accuracy: 0.6682\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.1354 - accuracy: 0.6707\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.1298 - accuracy: 0.6713\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.1244 - accuracy: 0.6728\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.1189 - accuracy: 0.6738\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.1147 - accuracy: 0.6755\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.1125 - accuracy: 0.6746\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.1158 - accuracy: 0.6746\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.1420 - accuracy: 0.6650\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Training base branch:\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 1.3777 - accuracy: 0.6144\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.3616 - accuracy: 0.6115\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.3586 - accuracy: 0.6135\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.3565 - accuracy: 0.6211\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.3464 - accuracy: 0.6249\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.3487 - accuracy: 0.6147\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.3315 - accuracy: 0.6255\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.3394 - accuracy: 0.6258\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.3235 - accuracy: 0.6302\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.3307 - accuracy: 0.6211\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.3145 - accuracy: 0.6321\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.3192 - accuracy: 0.6319\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.3080 - accuracy: 0.6337\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.3086 - accuracy: 0.6310\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.3036 - accuracy: 0.6360\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.2964 - accuracy: 0.6386\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.2984 - accuracy: 0.6334\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.2870 - accuracy: 0.6409\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.2888 - accuracy: 0.6407\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.2825 - accuracy: 0.6410\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.2767 - accuracy: 0.6434\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.2773 - accuracy: 0.6436\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.2690 - accuracy: 0.6454\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.2671 - accuracy: 0.6456\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.2645 - accuracy: 0.6478\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.2586 - accuracy: 0.6491\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.2548 - accuracy: 0.6502\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.2535 - accuracy: 0.6516\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.2490 - accuracy: 0.6516\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.2429 - accuracy: 0.6543\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.2404 - accuracy: 0.6554\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.2378 - accuracy: 0.6550\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.2349 - accuracy: 0.6569\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.2316 - accuracy: 0.6569\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.2269 - accuracy: 0.6592\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.2226 - accuracy: 0.6598\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.2192 - accuracy: 0.6618\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.2151 - accuracy: 0.6620\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.2122 - accuracy: 0.6636\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.2113 - accuracy: 0.6620\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "mean split score: 0.603066\n",
            "mean base score: 0.586341\n",
            "mean_diff: 0.016725\n",
            "mean_diff_base_before: 0.035015\n",
            "es: 0.477642\n",
            "mean_diff: 0.017, std_diff: 0.274, std_score: 0.489, es: 0.478\n",
            "df: 802816.00, test_stat: 54.662, cv_apx: 2.326\n",
            "= Branch 00 not split\n",
            "Level 2 -- branch: 01 --------------------------------------------------\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "log_lr < 0: check initialization!\n",
            "Training new branches...\n",
            "Training branch 0:\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.2568 - accuracy: 0.6260\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.2486 - accuracy: 0.6246\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.2393 - accuracy: 0.6373\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.2192 - accuracy: 0.6372\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.2060 - accuracy: 0.6421\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.1964 - accuracy: 0.6515\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.1857 - accuracy: 0.6506\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.1746 - accuracy: 0.6611\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.1564 - accuracy: 0.6630\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.1395 - accuracy: 0.6696\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.1331 - accuracy: 0.6736\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.1265 - accuracy: 0.6741\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.1130 - accuracy: 0.6866\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.0985 - accuracy: 0.6852\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.0822 - accuracy: 0.6959\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.0714 - accuracy: 0.7010\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.0680 - accuracy: 0.6987\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.0650 - accuracy: 0.7055\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.0641 - accuracy: 0.6984\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.0696 - accuracy: 0.7029\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.0709 - accuracy: 0.6992\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.0217 - accuracy: 0.7174\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.0357 - accuracy: 0.7125\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.0363 - accuracy: 0.7109\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.0154 - accuracy: 0.7218\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1.0110 - accuracy: 0.7198\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9978 - accuracy: 0.7200\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.0050 - accuracy: 0.7241\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.9743 - accuracy: 0.7312\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.9987 - accuracy: 0.7176\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9757 - accuracy: 0.7338\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9816 - accuracy: 0.7271\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.9656 - accuracy: 0.7288\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.9658 - accuracy: 0.7332\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9529 - accuracy: 0.7358\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9543 - accuracy: 0.7368\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9300 - accuracy: 0.7449\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9475 - accuracy: 0.7366\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9219 - accuracy: 0.7470\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9247 - accuracy: 0.7466\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Training branch 1:\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.0481 - accuracy: 0.6788\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.0809 - accuracy: 0.6720\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.1898 - accuracy: 0.6371\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.0130 - accuracy: 0.6914\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.1711 - accuracy: 0.6420\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.0447 - accuracy: 0.6759\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.1178 - accuracy: 0.6553\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.0049 - accuracy: 0.6868\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.0415 - accuracy: 0.6803\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.0235 - accuracy: 0.6846\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.9807 - accuracy: 0.7018\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.0063 - accuracy: 0.6887\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9825 - accuracy: 0.6917\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.9720 - accuracy: 0.7042\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.9590 - accuracy: 0.7030\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.9589 - accuracy: 0.7004\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.9503 - accuracy: 0.7058\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.9370 - accuracy: 0.7071\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9333 - accuracy: 0.7101\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.9271 - accuracy: 0.7118\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9208 - accuracy: 0.7138\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.9083 - accuracy: 0.7182\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9096 - accuracy: 0.7183\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.9020 - accuracy: 0.7166\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.8876 - accuracy: 0.7201\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.8898 - accuracy: 0.7214\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.8818 - accuracy: 0.7242\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.8714 - accuracy: 0.7260\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.8690 - accuracy: 0.7274\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.8640 - accuracy: 0.7276\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.8558 - accuracy: 0.7286\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.8533 - accuracy: 0.7317\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.8464 - accuracy: 0.7344\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.8402 - accuracy: 0.7354\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.8378 - accuracy: 0.7363\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.8301 - accuracy: 0.7375\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.8260 - accuracy: 0.7393\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.8222 - accuracy: 0.7413\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.8151 - accuracy: 0.7433\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.8130 - accuracy: 0.7443\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Training base branch:\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.1524 - accuracy: 0.6524\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.1469 - accuracy: 0.6535\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.1375 - accuracy: 0.6574\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.1295 - accuracy: 0.6605\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.1242 - accuracy: 0.6614\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.1219 - accuracy: 0.6624\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.1198 - accuracy: 0.6636\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.1173 - accuracy: 0.6647\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.1113 - accuracy: 0.6659\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.1022 - accuracy: 0.6699\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.0929 - accuracy: 0.6728\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0858 - accuracy: 0.6748\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0815 - accuracy: 0.6764\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.0797 - accuracy: 0.6768\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0801 - accuracy: 0.6774\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0826 - accuracy: 0.6756\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0844 - accuracy: 0.6759\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.0715 - accuracy: 0.6795\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.0526 - accuracy: 0.6863\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.0481 - accuracy: 0.6885\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.0532 - accuracy: 0.6863\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.0508 - accuracy: 0.6877\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.0340 - accuracy: 0.6930\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0270 - accuracy: 0.6956\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.0297 - accuracy: 0.6945\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.0266 - accuracy: 0.6950\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.0169 - accuracy: 0.6996\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.0117 - accuracy: 0.7014\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.0182 - accuracy: 0.6979\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.0317 - accuracy: 0.6968\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.0161 - accuracy: 0.6985\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.9963 - accuracy: 0.7061\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.9952 - accuracy: 0.7082\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.9982 - accuracy: 0.7066\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.9861 - accuracy: 0.7112\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.9706 - accuracy: 0.7165\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.9797 - accuracy: 0.7139\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.9754 - accuracy: 0.7152\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.9659 - accuracy: 0.7175\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.9744 - accuracy: 0.7149\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "mean split score: 0.691288\n",
            "mean base score: 0.663015\n",
            "mean_diff: 0.028273\n",
            "mean_diff_base_before: 0.036691\n",
            "es: 0.770577\n",
            "mean_diff: 0.028, std_diff: 0.291, std_score: 0.462, es: 0.771\n",
            "df: 786432.00, test_stat: 86.305, cv_apx: 2.326\n",
            "= Branch 01 not split\n",
            "Level 2 -- branch: 10 --------------------------------------------------\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "log_lr < 0: check initialization!\n",
            "Training new branches...\n",
            "Training branch 0:\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.1168 - accuracy: 0.6808\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 1.1095 - accuracy: 0.6827\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.1018 - accuracy: 0.6851\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.0930 - accuracy: 0.6879\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.0846 - accuracy: 0.6901\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.0810 - accuracy: 0.6888\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.0925 - accuracy: 0.6872\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.1109 - accuracy: 0.6779\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1.1042 - accuracy: 0.6824\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.0514 - accuracy: 0.6946\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.1071 - accuracy: 0.6738\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1.0559 - accuracy: 0.6935\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.0668 - accuracy: 0.6902\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 1.0427 - accuracy: 0.6947\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.0453 - accuracy: 0.6936\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.0304 - accuracy: 0.6976\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.0355 - accuracy: 0.6958\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.0132 - accuracy: 0.7013\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.0231 - accuracy: 0.6993\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.0022 - accuracy: 0.7049\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.0105 - accuracy: 0.7006\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9899 - accuracy: 0.7068\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.9988 - accuracy: 0.7035\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9801 - accuracy: 0.7084\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.9855 - accuracy: 0.7064\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9707 - accuracy: 0.7112\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9753 - accuracy: 0.7111\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.9591 - accuracy: 0.7144\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9634 - accuracy: 0.7117\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9498 - accuracy: 0.7167\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9522 - accuracy: 0.7181\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9416 - accuracy: 0.7195\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9395 - accuracy: 0.7194\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9340 - accuracy: 0.7233\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.9266 - accuracy: 0.7244\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9260 - accuracy: 0.7226\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9164 - accuracy: 0.7281\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.9157 - accuracy: 0.7287\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9110 - accuracy: 0.7288\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9037 - accuracy: 0.7307\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Training branch 1:\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.2984 - accuracy: 0.6417\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.2912 - accuracy: 0.6427\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.2839 - accuracy: 0.6449\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.2762 - accuracy: 0.6468\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.2676 - accuracy: 0.6486\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.2601 - accuracy: 0.6509\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.2530 - accuracy: 0.6526\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.2452 - accuracy: 0.6546\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.2383 - accuracy: 0.6566\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.2305 - accuracy: 0.6587\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.2228 - accuracy: 0.6610\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.2170 - accuracy: 0.6624\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.2117 - accuracy: 0.6643\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.2109 - accuracy: 0.6629\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.2165 - accuracy: 0.6638\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.2068 - accuracy: 0.6636\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.1870 - accuracy: 0.6707\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.1790 - accuracy: 0.6728\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.1852 - accuracy: 0.6697\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.1845 - accuracy: 0.6711\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.1634 - accuracy: 0.6760\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.1613 - accuracy: 0.6760\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.1646 - accuracy: 0.6761\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.1467 - accuracy: 0.6795\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.1417 - accuracy: 0.6807\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.1439 - accuracy: 0.6816\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.1295 - accuracy: 0.6844\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.1255 - accuracy: 0.6852\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.1270 - accuracy: 0.6868\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.1149 - accuracy: 0.6888\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.1071 - accuracy: 0.6902\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.1071 - accuracy: 0.6928\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.0999 - accuracy: 0.6922\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.0908 - accuracy: 0.6956\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.0874 - accuracy: 0.6979\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.0862 - accuracy: 0.6952\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.0826 - accuracy: 0.6997\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.0727 - accuracy: 0.6991\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.0659 - accuracy: 0.7025\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.0653 - accuracy: 0.7031\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Training base branch:\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 1.2132 - accuracy: 0.6601\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.2096 - accuracy: 0.6608\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.2056 - accuracy: 0.6624\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.2013 - accuracy: 0.6634\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.1969 - accuracy: 0.6648\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.1929 - accuracy: 0.6658\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.1890 - accuracy: 0.6668\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.1855 - accuracy: 0.6677\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.1830 - accuracy: 0.6682\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.1824 - accuracy: 0.6684\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.1890 - accuracy: 0.6659\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.1928 - accuracy: 0.6650\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.1898 - accuracy: 0.6653\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.1634 - accuracy: 0.6729\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.1718 - accuracy: 0.6711\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.1793 - accuracy: 0.6671\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.1539 - accuracy: 0.6753\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.1657 - accuracy: 0.6718\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.1627 - accuracy: 0.6717\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.1464 - accuracy: 0.6768\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.1565 - accuracy: 0.6748\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.1426 - accuracy: 0.6771\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.1418 - accuracy: 0.6772\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.1353 - accuracy: 0.6799\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.1359 - accuracy: 0.6790\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.1323 - accuracy: 0.6797\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.1235 - accuracy: 0.6823\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.1318 - accuracy: 0.6802\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.1159 - accuracy: 0.6842\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.1172 - accuracy: 0.6835\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.1122 - accuracy: 0.6854\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.1060 - accuracy: 0.6873\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.1067 - accuracy: 0.6859\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.0973 - accuracy: 0.6889\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.1014 - accuracy: 0.6883\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.0952 - accuracy: 0.6889\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.0904 - accuracy: 0.6905\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.0910 - accuracy: 0.6903\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.0819 - accuracy: 0.6928\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.0800 - accuracy: 0.6931\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "mean split score: 0.663411\n",
            "mean base score: 0.648257\n",
            "mean_diff: 0.015155\n",
            "mean_diff_base_before: 0.018454\n",
            "es: 0.821195\n",
            "mean_diff: 0.015, std_diff: 0.240, std_score: 0.473, es: 0.821\n",
            "df: 786432.00, test_stat: 56.070, cv_apx: 2.326\n",
            "+ Split 10 into 100, 101\n",
            "Level 2 -- branch: 11 --------------------------------------------------\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "log_lr < 0: check initialization!\n",
            "Training new branches...\n",
            "Training branch 0:\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.7536 - accuracy: 0.7895\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.7461 - accuracy: 0.7915\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.7355 - accuracy: 0.7952\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7277 - accuracy: 0.7983\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7193 - accuracy: 0.8000\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.7116 - accuracy: 0.8020\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.7053 - accuracy: 0.8045\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6965 - accuracy: 0.8073\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6883 - accuracy: 0.8104\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6823 - accuracy: 0.8131\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6762 - accuracy: 0.8156\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6684 - accuracy: 0.8179\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6611 - accuracy: 0.8200\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6544 - accuracy: 0.8218\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.6485 - accuracy: 0.8234\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6437 - accuracy: 0.8242\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.6404 - accuracy: 0.8251\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6415 - accuracy: 0.8249\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6353 - accuracy: 0.8260\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6322 - accuracy: 0.8271\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6201 - accuracy: 0.8298\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6183 - accuracy: 0.8306\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6239 - accuracy: 0.8291\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6092 - accuracy: 0.8308\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6078 - accuracy: 0.8322\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6229 - accuracy: 0.8277\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.5981 - accuracy: 0.8330\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6100 - accuracy: 0.8323\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6318 - accuracy: 0.8277\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.6116 - accuracy: 0.8317\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6127 - accuracy: 0.8310\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.5979 - accuracy: 0.8330\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5905 - accuracy: 0.8357\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.5903 - accuracy: 0.8343\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5832 - accuracy: 0.8382\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.5814 - accuracy: 0.8369\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5748 - accuracy: 0.8383\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5744 - accuracy: 0.8386\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5667 - accuracy: 0.8425\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5691 - accuracy: 0.8402\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Training branch 1:\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.0967 - accuracy: 0.7064\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.0885 - accuracy: 0.7076\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.0853 - accuracy: 0.7081\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.0807 - accuracy: 0.7112\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.0741 - accuracy: 0.7138\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.0574 - accuracy: 0.7166\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.0412 - accuracy: 0.7197\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.0324 - accuracy: 0.7234\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.0294 - accuracy: 0.7257\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.0189 - accuracy: 0.7271\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.0061 - accuracy: 0.7326\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.9991 - accuracy: 0.7352\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9950 - accuracy: 0.7337\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.9836 - accuracy: 0.7397\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.9719 - accuracy: 0.7422\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9635 - accuracy: 0.7450\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.9582 - accuracy: 0.7479\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.9513 - accuracy: 0.7464\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.9432 - accuracy: 0.7512\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.9338 - accuracy: 0.7515\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9251 - accuracy: 0.7562\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.9168 - accuracy: 0.7561\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9091 - accuracy: 0.7596\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9023 - accuracy: 0.7593\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8984 - accuracy: 0.7622\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9071 - accuracy: 0.7532\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9487 - accuracy: 0.7448\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9791 - accuracy: 0.7275\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.8835 - accuracy: 0.7684\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.9221 - accuracy: 0.7567\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8886 - accuracy: 0.7555\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8886 - accuracy: 0.7543\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.8778 - accuracy: 0.7633\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.8706 - accuracy: 0.7669\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8610 - accuracy: 0.7643\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.8619 - accuracy: 0.7629\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8430 - accuracy: 0.7746\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8532 - accuracy: 0.7695\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8307 - accuracy: 0.7729\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8407 - accuracy: 0.7659\n",
            "1/1 [==============================] - 1s 615ms/step\n",
            "Training base branch:\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "2\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.9215 - accuracy: 0.7488\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.9168 - accuracy: 0.7502\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.9128 - accuracy: 0.7514\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.9085 - accuracy: 0.7526\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.9042 - accuracy: 0.7541\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.9001 - accuracy: 0.7553\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.8961 - accuracy: 0.7565\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.8937 - accuracy: 0.7567\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.8948 - accuracy: 0.7571\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.9097 - accuracy: 0.7530\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.9125 - accuracy: 0.7517\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.8920 - accuracy: 0.7579\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.8780 - accuracy: 0.7618\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.8959 - accuracy: 0.7576\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.8766 - accuracy: 0.7619\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.8715 - accuracy: 0.7635\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.8783 - accuracy: 0.7631\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.8588 - accuracy: 0.7680\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.8662 - accuracy: 0.7656\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.8560 - accuracy: 0.7693\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.8518 - accuracy: 0.7702\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.8557 - accuracy: 0.7679\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.8423 - accuracy: 0.7731\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.8455 - accuracy: 0.7722\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.8422 - accuracy: 0.7728\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.8333 - accuracy: 0.7754\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.8381 - accuracy: 0.7741\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.8312 - accuracy: 0.7753\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.8245 - accuracy: 0.7774\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.8280 - accuracy: 0.7773\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.8216 - accuracy: 0.7779\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.8150 - accuracy: 0.7803\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.8176 - accuracy: 0.7796\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.8136 - accuracy: 0.7799\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.8057 - accuracy: 0.7828\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.8063 - accuracy: 0.7828\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.8055 - accuracy: 0.7822\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.7982 - accuracy: 0.7851\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.7944 - accuracy: 0.7859\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.7951 - accuracy: 0.7850\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "mean split score: 0.778006\n",
            "mean base score: 0.763786\n",
            "mean_diff: 0.014220\n",
            "mean_diff_base_before: 0.026217\n",
            "es: 0.542401\n",
            "mean_diff: 0.014, std_diff: 0.234, std_score: 0.416, es: 0.542\n",
            "df: 770048.00, test_stat: 53.320, cv_apx: 2.326\n",
            "= Branch 11 not split\n",
            "Level 3 --------------------------------------------------\n",
            "Level 3 -- branch: 100 --------------------------------------------------\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Training new branches...\n",
            "Training branch 0:\n",
            "2\n",
            "Epoch 121/160\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.9456 - accuracy: 0.7342\n",
            "Epoch 122/160\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.9388 - accuracy: 0.7329\n",
            "Epoch 123/160\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.9271 - accuracy: 0.7361\n",
            "Epoch 124/160\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.9323 - accuracy: 0.7310\n",
            "Epoch 125/160\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.9810 - accuracy: 0.7081\n",
            "Epoch 126/160\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.9482 - accuracy: 0.7244\n",
            "Epoch 127/160\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.8860 - accuracy: 0.7448\n",
            "Epoch 128/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.9112 - accuracy: 0.7261\n",
            "Epoch 129/160\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.8835 - accuracy: 0.7456\n",
            "Epoch 130/160\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.8696 - accuracy: 0.7481\n",
            "Epoch 131/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.8745 - accuracy: 0.7363\n",
            "Epoch 132/160\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.8461 - accuracy: 0.7522\n",
            "Epoch 133/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.8612 - accuracy: 0.7464\n",
            "Epoch 134/160\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.8325 - accuracy: 0.7589\n",
            "Epoch 135/160\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.8387 - accuracy: 0.7458\n",
            "Epoch 136/160\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.8175 - accuracy: 0.7653\n",
            "Epoch 137/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.8221 - accuracy: 0.7648\n",
            "Epoch 138/160\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.8040 - accuracy: 0.7646\n",
            "Epoch 139/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.8085 - accuracy: 0.7597\n",
            "Epoch 140/160\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7926 - accuracy: 0.7760\n",
            "Epoch 141/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7973 - accuracy: 0.7737\n",
            "Epoch 142/160\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7883 - accuracy: 0.7760\n",
            "Epoch 143/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7962 - accuracy: 0.7607\n",
            "Epoch 144/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7979 - accuracy: 0.7787\n",
            "Epoch 145/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7963 - accuracy: 0.7727\n",
            "Epoch 146/160\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7772 - accuracy: 0.7805\n",
            "Epoch 147/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7646 - accuracy: 0.7833\n",
            "Epoch 148/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7671 - accuracy: 0.7843\n",
            "Epoch 149/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7579 - accuracy: 0.7925\n",
            "Epoch 150/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7533 - accuracy: 0.7880\n",
            "Epoch 151/160\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7472 - accuracy: 0.7893\n",
            "Epoch 152/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7484 - accuracy: 0.7950\n",
            "Epoch 153/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7379 - accuracy: 0.7959\n",
            "Epoch 154/160\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.7372 - accuracy: 0.7917\n",
            "Epoch 155/160\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7331 - accuracy: 0.7982\n",
            "Epoch 156/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7360 - accuracy: 0.7956\n",
            "Epoch 157/160\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7229 - accuracy: 0.8014\n",
            "Epoch 158/160\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7221 - accuracy: 0.7977\n",
            "Epoch 159/160\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7151 - accuracy: 0.8014\n",
            "Epoch 160/160\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7177 - accuracy: 0.8039\n",
            "1/1 [==============================] - 0s 449ms/step\n",
            "Training branch 1:\n",
            "2\n",
            "Epoch 121/160\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8751 - accuracy: 0.7336\n",
            "Epoch 122/160\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.9087 - accuracy: 0.7219\n",
            "Epoch 123/160\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.9226 - accuracy: 0.7229\n",
            "Epoch 124/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.9465 - accuracy: 0.7161\n",
            "Epoch 125/160\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8999 - accuracy: 0.7250\n",
            "Epoch 126/160\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8818 - accuracy: 0.7360\n",
            "Epoch 127/160\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.8902 - accuracy: 0.7321\n",
            "Epoch 128/160\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.8508 - accuracy: 0.7412\n",
            "Epoch 129/160\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8750 - accuracy: 0.7290\n",
            "Epoch 130/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8428 - accuracy: 0.7428\n",
            "Epoch 131/160\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.8365 - accuracy: 0.7481\n",
            "Epoch 132/160\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.8455 - accuracy: 0.7448\n",
            "Epoch 133/160\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.8121 - accuracy: 0.7531\n",
            "Epoch 134/160\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.8192 - accuracy: 0.7455\n",
            "Epoch 135/160\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.8149 - accuracy: 0.7463\n",
            "Epoch 136/160\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.7947 - accuracy: 0.7560\n",
            "Epoch 137/160\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7987 - accuracy: 0.7609\n",
            "Epoch 138/160\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.7833 - accuracy: 0.7607\n",
            "Epoch 139/160\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.7757 - accuracy: 0.7591\n",
            "Epoch 140/160\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.7794 - accuracy: 0.7579\n",
            "Epoch 141/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.7615 - accuracy: 0.7626\n",
            "Epoch 142/160\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7582 - accuracy: 0.7672\n",
            "Epoch 143/160\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.7568 - accuracy: 0.7700\n",
            "Epoch 144/160\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.7438 - accuracy: 0.7704\n",
            "Epoch 145/160\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.7427 - accuracy: 0.7700\n",
            "Epoch 146/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.7350 - accuracy: 0.7742\n",
            "Epoch 147/160\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.7289 - accuracy: 0.7770\n",
            "Epoch 148/160\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.7244 - accuracy: 0.7831\n",
            "Epoch 149/160\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7170 - accuracy: 0.7849\n",
            "Epoch 150/160\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7160 - accuracy: 0.7838\n",
            "Epoch 151/160\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7047 - accuracy: 0.7901\n",
            "Epoch 152/160\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7014 - accuracy: 0.7935\n",
            "Epoch 153/160\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6967 - accuracy: 0.7933\n",
            "Epoch 154/160\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6907 - accuracy: 0.7982\n",
            "Epoch 155/160\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6873 - accuracy: 0.7955\n",
            "Epoch 156/160\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6872 - accuracy: 0.8053\n",
            "Epoch 157/160\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7107 - accuracy: 0.7772\n",
            "Epoch 158/160\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.7703 - accuracy: 0.7621\n",
            "Epoch 159/160\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8870 - accuracy: 0.7389\n",
            "Epoch 160/160\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6837 - accuracy: 0.7952\n",
            "1/1 [==============================] - 0s 490ms/step\n",
            "Training base branch:\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2\n",
            "Epoch 121/160\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9057 - accuracy: 0.7338\n",
            "Epoch 122/160\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.9121 - accuracy: 0.7265\n",
            "Epoch 123/160\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.9327 - accuracy: 0.7230\n",
            "Epoch 124/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.9905 - accuracy: 0.7042\n",
            "Epoch 125/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8916 - accuracy: 0.7354\n",
            "Epoch 126/160\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.0287 - accuracy: 0.6916\n",
            "Epoch 127/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9565 - accuracy: 0.7135\n",
            "Epoch 128/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1.0084 - accuracy: 0.6994\n",
            "Epoch 129/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8985 - accuracy: 0.7339\n",
            "Epoch 130/160\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9621 - accuracy: 0.7213\n",
            "Epoch 131/160\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.9267 - accuracy: 0.7289\n",
            "Epoch 132/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8995 - accuracy: 0.7330\n",
            "Epoch 133/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9349 - accuracy: 0.7197\n",
            "Epoch 134/160\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.8999 - accuracy: 0.7303\n",
            "Epoch 135/160\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.8952 - accuracy: 0.7362\n",
            "Epoch 136/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.9101 - accuracy: 0.7343\n",
            "Epoch 137/160\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.8835 - accuracy: 0.7379\n",
            "Epoch 138/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8764 - accuracy: 0.7365\n",
            "Epoch 139/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8933 - accuracy: 0.7324\n",
            "Epoch 140/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8695 - accuracy: 0.7398\n",
            "Epoch 141/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8610 - accuracy: 0.7433\n",
            "Epoch 142/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8752 - accuracy: 0.7404\n",
            "Epoch 143/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8604 - accuracy: 0.7449\n",
            "Epoch 144/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8482 - accuracy: 0.7464\n",
            "Epoch 145/160\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.8568 - accuracy: 0.7434\n",
            "Epoch 146/160\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.8514 - accuracy: 0.7447\n",
            "Epoch 147/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8394 - accuracy: 0.7487\n",
            "Epoch 148/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8400 - accuracy: 0.7506\n",
            "Epoch 149/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8384 - accuracy: 0.7506\n",
            "Epoch 150/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8329 - accuracy: 0.7507\n",
            "Epoch 151/160\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.8272 - accuracy: 0.7529\n",
            "Epoch 152/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8249 - accuracy: 0.7547\n",
            "Epoch 153/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8247 - accuracy: 0.7551\n",
            "Epoch 154/160\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.8169 - accuracy: 0.7577\n",
            "Epoch 155/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8132 - accuracy: 0.7578\n",
            "Epoch 156/160\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.8144 - accuracy: 0.7563\n",
            "Epoch 157/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8071 - accuracy: 0.7589\n",
            "Epoch 158/160\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.8040 - accuracy: 0.7606\n",
            "Epoch 159/160\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.8027 - accuracy: 0.7608\n",
            "Epoch 160/160\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.7982 - accuracy: 0.7621\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "mean split score: 0.637701\n",
            "mean base score: 0.684966\n",
            "= Branch 100 not split\n",
            "Level 3 -- branch: 101 --------------------------------------------------\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "log_lr < 0: check initialization!\n",
            "Training new branches...\n",
            "Training branch 0:\n",
            "2\n",
            "Epoch 121/160\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 1.0841 - accuracy: 0.7010\n",
            "Epoch 122/160\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.0720 - accuracy: 0.7073\n",
            "Epoch 123/160\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.0553 - accuracy: 0.7107\n",
            "Epoch 124/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.0491 - accuracy: 0.7123\n",
            "Epoch 125/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.0437 - accuracy: 0.7192\n",
            "Epoch 126/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.0354 - accuracy: 0.7185\n",
            "Epoch 127/160\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1.0570 - accuracy: 0.7161\n",
            "Epoch 128/160\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.0905 - accuracy: 0.7020\n",
            "Epoch 129/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.0302 - accuracy: 0.7255\n",
            "Epoch 130/160\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.0058 - accuracy: 0.7322\n",
            "Epoch 131/160\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.0276 - accuracy: 0.7234\n",
            "Epoch 132/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.9824 - accuracy: 0.7393\n",
            "Epoch 133/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.0020 - accuracy: 0.7311\n",
            "Epoch 134/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.9689 - accuracy: 0.7399\n",
            "Epoch 135/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.9845 - accuracy: 0.7352\n",
            "Epoch 136/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.9549 - accuracy: 0.7446\n",
            "Epoch 137/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.9679 - accuracy: 0.7401\n",
            "Epoch 138/160\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.9422 - accuracy: 0.7470\n",
            "Epoch 139/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.9525 - accuracy: 0.7427\n",
            "Epoch 140/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.9310 - accuracy: 0.7488\n",
            "Epoch 141/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.9361 - accuracy: 0.7473\n",
            "Epoch 142/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.9213 - accuracy: 0.7516\n",
            "Epoch 143/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.9215 - accuracy: 0.7496\n",
            "Epoch 144/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.9087 - accuracy: 0.7537\n",
            "Epoch 145/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.9068 - accuracy: 0.7551\n",
            "Epoch 146/160\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.8984 - accuracy: 0.7567\n",
            "Epoch 147/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.8938 - accuracy: 0.7572\n",
            "Epoch 148/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8868 - accuracy: 0.7595\n",
            "Epoch 149/160\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.8822 - accuracy: 0.7620\n",
            "Epoch 150/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.8761 - accuracy: 0.7638\n",
            "Epoch 151/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8712 - accuracy: 0.7651\n",
            "Epoch 152/160\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.8648 - accuracy: 0.7670\n",
            "Epoch 153/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.8609 - accuracy: 0.7686\n",
            "Epoch 154/160\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.8546 - accuracy: 0.7704\n",
            "Epoch 155/160\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.8510 - accuracy: 0.7714\n",
            "Epoch 156/160\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8455 - accuracy: 0.7738\n",
            "Epoch 157/160\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.8409 - accuracy: 0.7743\n",
            "Epoch 158/160\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.8376 - accuracy: 0.7759\n",
            "Epoch 159/160\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.8319 - accuracy: 0.7764\n",
            "Epoch 160/160\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.8311 - accuracy: 0.7783\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Training branch 1:\n",
            "2\n",
            "Epoch 121/160\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0509 - accuracy: 0.7009\n",
            "Epoch 122/160\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.1131 - accuracy: 0.6856\n",
            "Epoch 123/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.1202 - accuracy: 0.6790\n",
            "Epoch 124/160\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.0705 - accuracy: 0.6986\n",
            "Epoch 125/160\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.0406 - accuracy: 0.7021\n",
            "Epoch 126/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.0333 - accuracy: 0.7053\n",
            "Epoch 127/160\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.0258 - accuracy: 0.7086\n",
            "Epoch 128/160\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.9925 - accuracy: 0.7151\n",
            "Epoch 129/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.0150 - accuracy: 0.7080\n",
            "Epoch 130/160\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.9759 - accuracy: 0.7190\n",
            "Epoch 131/160\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.9882 - accuracy: 0.7130\n",
            "Epoch 132/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.9546 - accuracy: 0.7271\n",
            "Epoch 133/160\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.9706 - accuracy: 0.7215\n",
            "Epoch 134/160\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.9426 - accuracy: 0.7255\n",
            "Epoch 135/160\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.9477 - accuracy: 0.7241\n",
            "Epoch 136/160\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.9376 - accuracy: 0.7278\n",
            "Epoch 137/160\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.9211 - accuracy: 0.7340\n",
            "Epoch 138/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.9278 - accuracy: 0.7323\n",
            "Epoch 139/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.9085 - accuracy: 0.7353\n",
            "Epoch 140/160\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.9101 - accuracy: 0.7333\n",
            "Epoch 141/160\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.9008 - accuracy: 0.7357\n",
            "Epoch 142/160\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8945 - accuracy: 0.7413\n",
            "Epoch 143/160\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8886 - accuracy: 0.7439\n",
            "Epoch 144/160\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8809 - accuracy: 0.7432\n",
            "Epoch 145/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8793 - accuracy: 0.7433\n",
            "Epoch 146/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8659 - accuracy: 0.7493\n",
            "Epoch 147/160\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8669 - accuracy: 0.7488\n",
            "Epoch 148/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8570 - accuracy: 0.7524\n",
            "Epoch 149/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8519 - accuracy: 0.7520\n",
            "Epoch 150/160\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8482 - accuracy: 0.7521\n",
            "Epoch 151/160\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8410 - accuracy: 0.7574\n",
            "Epoch 152/160\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8362 - accuracy: 0.7584\n",
            "Epoch 153/160\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8313 - accuracy: 0.7585\n",
            "Epoch 154/160\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8253 - accuracy: 0.7599\n",
            "Epoch 155/160\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8222 - accuracy: 0.7614\n",
            "Epoch 156/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8171 - accuracy: 0.7639\n",
            "Epoch 157/160\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8149 - accuracy: 0.7616\n",
            "Epoch 158/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8134 - accuracy: 0.7639\n",
            "Epoch 159/160\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8144 - accuracy: 0.7607\n",
            "Epoch 160/160\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8206 - accuracy: 0.7611\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Training base branch:\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2\n",
            "Epoch 121/160\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.0687 - accuracy: 0.7009\n",
            "Epoch 122/160\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.0755 - accuracy: 0.6998\n",
            "Epoch 123/160\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.0727 - accuracy: 0.7001\n",
            "Epoch 124/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.0615 - accuracy: 0.7009\n",
            "Epoch 125/160\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.0525 - accuracy: 0.7077\n",
            "Epoch 126/160\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.0510 - accuracy: 0.7058\n",
            "Epoch 127/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.0471 - accuracy: 0.7069\n",
            "Epoch 128/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.0341 - accuracy: 0.7117\n",
            "Epoch 129/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.0342 - accuracy: 0.7106\n",
            "Epoch 130/160\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.0378 - accuracy: 0.7099\n",
            "Epoch 131/160\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.0195 - accuracy: 0.7150\n",
            "Epoch 132/160\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.0168 - accuracy: 0.7153\n",
            "Epoch 133/160\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.0235 - accuracy: 0.7146\n",
            "Epoch 134/160\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.0069 - accuracy: 0.7185\n",
            "Epoch 135/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.0029 - accuracy: 0.7197\n",
            "Epoch 136/160\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.0093 - accuracy: 0.7188\n",
            "Epoch 137/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.9980 - accuracy: 0.7222\n",
            "Epoch 138/160\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.9894 - accuracy: 0.7243\n",
            "Epoch 139/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.9925 - accuracy: 0.7219\n",
            "Epoch 140/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.9856 - accuracy: 0.7259\n",
            "Epoch 141/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.9779 - accuracy: 0.7282\n",
            "Epoch 142/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.9779 - accuracy: 0.7267\n",
            "Epoch 143/160\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.9769 - accuracy: 0.7283\n",
            "Epoch 144/160\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.9685 - accuracy: 0.7296\n",
            "Epoch 145/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.9642 - accuracy: 0.7320\n",
            "Epoch 146/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.9651 - accuracy: 0.7323\n",
            "Epoch 147/160\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.9633 - accuracy: 0.7310\n",
            "Epoch 148/160\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.9560 - accuracy: 0.7347\n",
            "Epoch 149/160\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.9514 - accuracy: 0.7368\n",
            "Epoch 150/160\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.9533 - accuracy: 0.7346\n",
            "Epoch 151/160\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.9637 - accuracy: 0.7329\n",
            "Epoch 152/160\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.9757 - accuracy: 0.7260\n",
            "Epoch 153/160\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.9816 - accuracy: 0.7272\n",
            "Epoch 154/160\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.9545 - accuracy: 0.7359\n",
            "Epoch 155/160\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.9611 - accuracy: 0.7307\n",
            "Epoch 156/160\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.9587 - accuracy: 0.7337\n",
            "Epoch 157/160\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.9300 - accuracy: 0.7418\n",
            "Epoch 158/160\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.9484 - accuracy: 0.7358\n",
            "Epoch 159/160\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.9371 - accuracy: 0.7413\n",
            "Epoch 160/160\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.9242 - accuracy: 0.7441\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "mean split score: 0.699900\n",
            "mean base score: 0.680649\n",
            "mean_diff: 0.019250\n",
            "mean_diff_base_before: 0.023079\n",
            "es: 0.834127\n",
            "mean_diff: 0.019, std_diff: 0.255, std_score: 0.458, es: 0.834\n",
            "df: 409600.00, test_stat: 48.296, cv_apx: 2.326\n",
            "+ Split 101 into 1010, 1011\n",
            "Level 4 --------------------------------------------------\n",
            "Level 4 -- branch: 1010 --------------------------------------------------\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "sample size too small! returning\n",
            "Level 4 -- branch: 1011 --------------------------------------------------\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "sample size too small! returning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Save s_branch'''\n",
        "# print(s_branch)\n",
        "s_branch.to_pickle(dir + '/' + 's_branch.pkl')"
      ],
      "metadata": {
        "id": "DIU9WZ3o0QDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing"
      ],
      "metadata": {
        "id": "QB9iRxrIl1FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Run following if using an existing model without training'''\n",
        "#load model\n",
        "# model = UNetmodel(ckpt_path = dir_ckpt)#careful with name overload (model is used as a package, though with from ... import ...)\n",
        "\n",
        "#load learned partitioning\n",
        "# import pandas as pd\n",
        "# s_branch = pd.read_pickle(dir + '/' + 's_branch.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vil0Toa5mGeB",
        "outputId": "3a4b4644-a2a4-4145-b3bb-ba18f8506e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check ckpt path: result_auto_10/checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Testing'''\n",
        "from models import predict_test, predict_test_one_branch\n",
        "test_list = np.where(X_set == 0)\n",
        "\n",
        "np.set_printoptions(precision=2, suppress = True)"
      ],
      "metadata": {
        "id": "dtwwLbZ67HWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making prediction using the heterogeneity-aware model learned by STAR"
      ],
      "metadata": {
        "id": "gJybbvFBTR0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STAR\n",
        "pre, rec, f1, n_samples = predict_test(model, X[test_list], y[test_list], X_group[test_list], s_branch)\n",
        "# print('pre:', pre, 'rec:', rec, 'f1:', f1)\n",
        "print('STAR:')\n",
        "print('f1:', f1)\n",
        "print('weighted f1:', (f1@n_samples)/np.sum(n_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWQvQlbwZdZr",
        "outputId": "8db7b16d-97d5-44fd-ab65-2df0b8bc094f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "STAR:\n",
            "f1: [0.01 0.24 0.74 0.12 0.11 0.28 0.   0.49 0.   0.   0.6  0.   0.6  0.\n",
            " 0.   0.52 0.57 0.   0.48 0.18 0.68 0.   0.03]\n",
            "weighted f1: 0.5097734684865929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1hGjY8lqo0ImpPj9LC-v5HRrtHXy2RCOo/spatialnet_test/1python_code/metrics.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
            "  pre = true_class / pred_class\n",
            "/content/drive/.shortcut-targets-by-id/1hGjY8lqo0ImpPj9LC-v5HRrtHXy2RCOo/spatialnet_test/1python_code/metrics.py:18: RuntimeWarning: divide by zero encountered in reciprocal\n",
            "  f1 = 2/(pre_fix**(-1) + rec_fix**(-1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making predictions using the model without data partitioning. This is a simplified base model."
      ],
      "metadata": {
        "id": "_cXDWvyNTXBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#base\n",
        "model.load('')\n",
        "pre_base, rec_base, f1_base, n_samples_base = predict_test_one_branch(model, X[test_list], y[test_list])\n",
        "print('Base:')\n",
        "print('f1:', f1_base)\n",
        "print('weighted f1:', (f1_base@n_samples_base)/np.sum(n_samples_base))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8M7fo7f7KYm",
        "outputId": "7d6b0889-4d6f-4f76-9c37-cd5fa4b404b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Base:\n",
            "f1: [0.   0.   0.04 0.   0.   0.   0.   0.37 0.   0.   0.43 0.   0.27 0.\n",
            " 0.   0.26 0.   0.   0.   0.   0.62 0.   0.  ]\n",
            "weighted f1: 0.27972421230186273\n"
          ]
        }
      ]
    }
  ]
}